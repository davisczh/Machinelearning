{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a and 1b: Function to estimate emission params using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get emission counts from a given file list\n",
    "def get_emission_counts (file):\n",
    "    emission_count = {} # Stores the count of tag corresponding to each work\n",
    "    # Returns a dict of format {'Word1':{'O':count,'B-positive':count, ...}, 'Word2':{'O':count,'B-positive':count, ...}, ... }\n",
    "    tag_count = {'O':0,'B-positive':0,'B-neutral':0,'B-negative':0,'I-positive':0,'I-neutral':0,'I-negative':0} # Stores the total count of each tag\n",
    "    new_count = {'O':0,'B-positive':0,'B-neutral':0,'B-negative':0,'I-positive':0,'I-neutral':0,'I-negative':0} # Stores the counts for each line\n",
    "    for line in file:   # [Word Tag\\n] \n",
    "        if line != \"\\n\":\n",
    "            wordlist = line.split(\" \")  # [\"Word\",\"Tag\\n\"] \n",
    "       \n",
    "            word = ''.join([_ for _ in wordlist[:-1]])  # \"Word\"\n",
    "            tag = wordlist[-1].strip() # Remove trailing \\n  # \"Tag\"\n",
    "            if word not in emission_count:\n",
    "                emission_count[word] = deepcopy(new_count)\n",
    "            emission_count[word][tag] += 1\n",
    "            tag_count[tag] += 1\n",
    "    return emission_count, tag_count\n",
    "\n",
    "# Estimate the emission parameters using the given formula.\n",
    "# k is used to include words not appearing in the training set.\n",
    "def estimate_emission_params (file, k):\n",
    "    emission_count, tag_count = get_emission_counts(file)\n",
    "    emission_params = {}\n",
    "    # Returns a dict of format {'Word1':{'O':param,'B-positive':param, ...}, 'Word2':{'O':param,'B-positive':param, ...}, ... }\n",
    "    tag_prob = {'O':0,'B-positive':0,'B-neutral':0,'B-negative':0,'I-positive':0,'I-neutral':0,'I-negative':0} # Stores the tag probability of each word\n",
    "    emission_params[\"#UNK#\"] = deepcopy(tag_prob)\n",
    "    for tag in tag_count.keys():\n",
    "        den = tag_count[tag] + k\n",
    "        for word in emission_count.keys():\n",
    "            if word not in emission_params:\n",
    "                emission_params[word] = deepcopy(tag_prob)\n",
    "            num = 0\n",
    "            num += emission_count[word][tag]\n",
    "            emission_params[word][tag] = num/den\n",
    "        emission_params[\"#UNK#\"][tag] = k/den\n",
    "    return emission_params\n",
    "\n",
    "# Using the emission params obtained, perform simple sentiment analysis, returning a list containing the predicted outputs\n",
    "def sentiment_analysis(file, emission_params):\n",
    "    lines = []  # List containing \"Word Tag\\n\"\n",
    "    for line in file:\n",
    "        add = \"\"\n",
    "        word = line.strip()\n",
    "        if line != \"\\n\":\n",
    "            if word not in emission_params:\n",
    "                assigned_tag = max(emission_params[\"#UNK#\"],key=emission_params[\"#UNK#\"].get)\n",
    "            else:\n",
    "                assigned_tag = max(emission_params[word],key=emission_params[word].get)\n",
    "            add = word + \" \" + assigned_tag\n",
    "        lines.append(add)\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting emission params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading lines from files\n",
    "with open('Data/ES/train', 'r', encoding=\"utf-8\") as f:\n",
    "    ES_train = f.readlines()\n",
    "with open('Data/ES/dev.in', 'r', encoding=\"utf-8\") as f:\n",
    "    ES_devin = f.readlines()\n",
    "with open('Data/ES/dev.out', 'r', encoding=\"utf-8\") as f:\n",
    "    ES_devout = f.readlines()\n",
    "with open('Data/RU/train', 'r', encoding=\"utf-8\") as f:\n",
    "    RU_train = f.readlines()\n",
    "with open('Data/RU/dev.in', 'r', encoding=\"utf-8\") as f:\n",
    "    RU_devin = f.readlines()\n",
    "with open('Data/RU/dev.out', 'r', encoding=\"utf-8\") as f:\n",
    "    RU_devout = f.readlines()\n",
    "\n",
    "# Estimating Emission Params\n",
    "ES_train_emission_params = estimate_emission_params (ES_train,1)\n",
    "RU_train_emission_params = estimate_emission_params (RU_train,1)\n",
    "\n",
    "\n",
    "emission_count, tag_count = get_emission_counts(ES_train)\n",
    "print(emission_count[\":\"])\n",
    "print(tag_count)\n",
    "print(ES_train_emission_params[\":\"])\n",
    "print(RU_train_emission_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Sentiment Analysis and Writing to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Sentiment analysis, returning lists of lines to be added\n",
    "ES_devout_lines = sentiment_analysis(ES_devin,ES_train_emission_params)\n",
    "RU_devout_lines = sentiment_analysis(RU_devin,RU_train_emission_params)\n",
    "\n",
    "# Writing to Files\n",
    "with open('Data/RU/dev.p1.out', 'w', encoding=\"utf-8\") as f:\n",
    "   f.write('\\n'.join(RU_devout_lines))\n",
    "\n",
    "with open('Data/ES/dev.p1.out', 'w', encoding=\"utf-8\") as f:\n",
    "   f.write('\\n'.join(ES_devout_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining precision, recall, and F scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading lines from dev.p1.out files\n",
    "with open('Data/ES/dev.p1.out', 'r', encoding=\"utf-8\") as f:\n",
    "    ES_p1_devout = f.readlines()\n",
    "with open('Data/RU/dev.p1.out', 'r', encoding=\"utf-8\") as f:\n",
    "    RU_p1_devout = f.readlines()\n",
    "\n",
    "a,b = get_emission_counts(ES_p1_devout)\n",
    "\n",
    "\n",
    "# We then run the eval script provided to obtain the different scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\projet\\\\evalResult.py\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\RU\\\\dev.out\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\RU\\\\dev.p1.out\",\n",
    "]\n",
    "command1 = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\projet\\\\evalResult.py\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\ES\\\\dev.out\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\ES\\\\dev.p1.out\",\n",
    "]\n",
    "\n",
    "result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "result1 = subprocess.run(command1, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "print('RU:\\n' + result.stdout)\n",
    "print('ES:\\n' + result1.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Error:\", result.stderr)\n",
    "if result.stderr:\n",
    "    print(\"Error:\", result1.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_transition_parameters(training_data):\n",
    "    tag_transition_count = {}\n",
    "    tag_count = {}\n",
    "\n",
    "    previous_tag = \"START\"\n",
    "    for line in training_data + ['\\n']:  # Adding an extra newline to process the last sentence\n",
    "        if line.strip() == '':\n",
    "            # Handle end of sentence\n",
    "            tag_transition_count[(previous_tag, \"END\")] = tag_transition_count.get((previous_tag, \"END\"), 0) + 1\n",
    "            tag_count[\"END\"] = tag_count.get(\"END\", 0) + 1\n",
    "            previous_tag = \"START\"\n",
    "        else:\n",
    "            tag = line.split(' ')[-1]\n",
    "            tag = tag.strip()\n",
    "            tag_transition_count[(previous_tag, tag)] = tag_transition_count.get((previous_tag, tag), 0) + 1\n",
    "            tag_count[previous_tag] = tag_count.get(previous_tag, 0) + 1\n",
    "            previous_tag = tag\n",
    "\n",
    "    tag_count[\"START\"] = len([line for line in training_data if line.strip() == '']) + 1\n",
    "\n",
    "    transition_parameters = {}\n",
    "    for (prev_tag, tag), count in tag_transition_count.items():\n",
    "        transition_parameters[(prev_tag, tag)] = 0 if tag_count[prev_tag] == 0 else count / tag_count[prev_tag]\n",
    "\n",
    "    return transition_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_train_transition_params= estimate_transition_parameters (ES_train)\n",
    "RU_train_transition_params = estimate_transition_parameters (RU_train)\n",
    "# print(ES_train_transition_params)\n",
    "# print(RU_train_emission_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ES_devin)\n",
    "# print(ES_train_transition_params)\n",
    "# print(RU_train_transition_params)\n",
    "# print(ES_train_emission_params)\n",
    "# print(RU_train_emission_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(words, emission_params, transition_params):\n",
    "    all_best_tags = []\n",
    "    sentence = []\n",
    "    for word in words + ['\\n']:  # Adding an extra newline to process the last sentence\n",
    "        if word.strip() == '':  # Sentence separator\n",
    "            if sentence:  # If there are words in the sentence\n",
    "                tags = list(emission_params[\"#UNK#\"].keys())\n",
    "                n = len(sentence)\n",
    "\n",
    "                viterbi_matrix = [{tag: 0 for tag in tags} for _ in range(n+1)]  # Add 1 for START\n",
    "                backpointers = [{tag: None for tag in tags} for _ in range(n+1)]\n",
    "\n",
    "                # Initialization step (t=0)\n",
    "                for tag in tags:\n",
    "                    viterbi_matrix[0][tag] = transition_params.get((\"START\", tag), 0) * emission_params.get(sentence[0].strip(), emission_params[\"#UNK#\"]).get(tag, 0)\n",
    "\n",
    "                # Recursion step (t > 0)\n",
    "                for t in range(1, n):\n",
    "                    for tag in tags:\n",
    "                        emission_prob = emission_params.get(sentence[t].strip(), emission_params[\"#UNK#\"]).get(tag, 0)\n",
    "                        max_score, prev_tag = max(\n",
    "                            [(viterbi_matrix[t-1][prev_tag] * transition_params.get((prev_tag, tag), 0) * emission_prob, prev_tag) for prev_tag in tags]\n",
    "                        )\n",
    "                        viterbi_matrix[t][tag] = max_score\n",
    "                        backpointers[t][tag] = prev_tag\n",
    "\n",
    "                # Termination step (t=n)\n",
    "                max_score, final_tag = max(\n",
    "                    [(viterbi_matrix[n-1][tag] * transition_params.get((tag, \"END\"), 0), tag) for tag in tags]\n",
    "                )\n",
    "\n",
    "                # Trace back the best path\n",
    "                best_tags = []  # Start with an empty line\n",
    "                best_tags.append((sentence[-1].strip(), final_tag))\n",
    "                for t in range(n-1, 0, -1):\n",
    "                    prev_word, prev_tag = best_tags[-1]\n",
    "                    best_tags.append((sentence[t-1].strip(), backpointers[t][prev_tag]))\n",
    "\n",
    "                best_tags.append(('', ''))  # End with an empty line\n",
    "                best_tags.reverse()\n",
    "                all_best_tags.append(best_tags)\n",
    "\n",
    "                sentence = []  # Reset the sentence\n",
    "        else:\n",
    "            sentence.append(word)\n",
    "\n",
    "    return all_best_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_tags_ES = sum(viterbi(ES_devin, ES_train_emission_params,  ES_train_transition_params), [])\n",
    "print(best_tags_ES)\n",
    "best_tags_RU = sum(viterbi(RU_devin, RU_train_emission_params,  RU_train_transition_params), [])\n",
    "print(best_tags_RU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming best_tags is a list of tuples containing (word, tag) pairs\n",
    "\n",
    "with open('Data/ES/dev.p2.out', 'w', encoding=\"utf-8\") as f:\n",
    "    lines = ['{} {}'.format(word, tag) for word, tag in best_tags_ES]\n",
    "    f.write('\\n'.join(lines))\n",
    "\n",
    "with open('Data/RU/dev.p2.out', 'w', encoding=\"utf-8\") as f:\n",
    "    lines = ['{} {}'.format(word, tag) for word, tag in best_tags_RU]\n",
    "    f.write('\\n'.join(lines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RU:\n",
      "\n",
      "#Entity in gold data: 389\n",
      "#Entity in prediction: 478\n",
      "\n",
      "#Correct Entity : 18\n",
      "Entity  precision: 0.0377\n",
      "Entity  recall: 0.0463\n",
      "Entity  F: 0.0415\n",
      "\n",
      "#Correct Sentiment : 12\n",
      "Sentiment  precision: 0.0251\n",
      "Sentiment  recall: 0.0308\n",
      "Sentiment  F: 0.0277\n",
      "\n",
      "ES:\n",
      "\n",
      "#Entity in gold data: 229\n",
      "#Entity in prediction: 306\n",
      "\n",
      "#Correct Entity : 11\n",
      "Entity  precision: 0.0359\n",
      "Entity  recall: 0.0480\n",
      "Entity  F: 0.0411\n",
      "\n",
      "#Correct Sentiment : 6\n",
      "Sentiment  precision: 0.0196\n",
      "Sentiment  recall: 0.0262\n",
      "Sentiment  F: 0.0224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\projet\\\\evalResult.py\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\RU\\\\dev.out\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\RU\\\\dev.p2.out\",\n",
    "]\n",
    "command1 = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\projet\\\\evalResult.py\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\ES\\\\dev.out\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\SUTD\\\\term 5\\\\ml\\\\Machinelearning\\\\Data\\\\ES\\\\dev.p2.out\",\n",
    "]\n",
    "\n",
    "result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "result1 = subprocess.run(command1, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "print('RU:\\n' + result.stdout)\n",
    "print('ES:\\n' + result1.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Error:\", result.stderr)\n",
    "if result.stderr:\n",
    "    print(\"Error:\", result1.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
